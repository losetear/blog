title: U3D进阶AI算法：GOAP
date: 2015-09-13 14:44:34
categories:
- AI
tags:
- Unity3D
- GOAP
- AI
---

##在这里先科普下常用的Ai架构： ##
###状态机### 
最简单的应该是状态机了，这应该是每个程序员都接触过的架构。简单易懂，优点非常明显，但是同样缺点也不少，首先编码量很大，大部分都是硬编码在里面，可读性和复用性很低。基本上已经在大型游戏里淘汰了。
###行为树### 
这是这几年最流行的ai架构了，从状态机延伸而来，最大的优点就是行为节点可复用性很高，可以自由的组合出想要的ai行为而不用重新去硬编码整个逻辑。缺点就是还依赖于ai设计师的架构，不够灵活。
###GOAP（Goal Oriented Action Planning）### 
就是本文的重点。从最早的FEAR到Stalker以及其他单机大作都是用GOAP实现AI。GOAP的优点在于它会根据设定的目标来搜索出所有的组合可能性，然后根据决策算法来找出最优的选项。比如我需要npc去填充肚子，他可能会去摘果子吃或者找把弓箭去打猎填饱肚子，这些都会根据当时的环境来动态决策，显得异常真实。

本文基于网上一个开源的GOAP实现算法改进而来，
源地址在这里：https://github.com/sploreg/goap。
##主要改进了GC和性能，改进后的算法地址：https://github.com/losetear/goap##

这里并不想对这个源码进行详细解释，原作者以及分享了一篇很棒的文章，而且网上也有了翻译，地址在这里：http://gamerboom.com/archives/83622 。
这里只是想记录对这个算法进行的一些改进，因为我也是刚接触不久，如有错误敬请指出，谢谢。

##名词解释##
1. Agent是执行主体，负责调度全局，并执行终端节点。包含三个主要的fsmstate，idleState用于在空闲时决策出下一个可用的行动链。moveToState用于一些需要移动到目标的action，performAction用于执行行动链。
2. GoapPlaner将找出可以完成当前目标的行动链，并且使用决策算法找出里面最优的。
3. GoapAction代表执行终端，有几个重要的参数：preconditions表示前提，执行这个终端必须通过前提测试。effects表示执行后产生的效果。Cost表示执行这个终端的消耗，Risk和Return组成了风险收益，用于决策整个行动链的优先级。

##算法过程##
1. Agent执行idleState，找出执行者相关的环境变量和Goal排序表(Brain通过决策算法计算出当前的Goal权重)
2. Agent通过优先级遍历Goal
3. Planer接受当前可执行的所有Action和Goal，来决策出一个最优的行动链。如果完成不了Goal，返回空值让Agent遍历下一个Goal。
4. Agent跳转到PerformAction，执行行动链。

##优化方案##
1. 每次执行Action都会调用FindObjectsOfType，从而降低性能。解决方法：增加BlackBoard类，每个实体保存一份自己的数据，在创建的时候初始化一次即可。
2. Planer在生成行动链的时候递归过多从而导致创建了过多的临时变量。解决方法：找出GC瓶颈，将之回收复用，降低GC频率。

